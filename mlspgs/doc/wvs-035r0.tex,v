head	1.1;
access;
symbols
	v5-02-NRT-19:1.1
	v6-00:1.1
	v5-02-NRT-18:1.1
	v5-02:1.1
	v5-01-NRT-17:1.1
	v5-01-NRT-16:1.1
	v5-01-NRT-15:1.1
	v5-01-NRT-14:1.1
	neuralnetworks-1-0:1.1.0.14
	cfm-single-freq-0-1:1.1.0.12
	v5-01:1.1
	v5-00:1.1
	v4-23-TA133:1.1.0.10
	mus-emls-1-70:1.1.0.8
	rel-1-0-englocks-work:1.1.0.6
	VUMLS1-00:1.1
	VPL1-00:1.1
	V4-22-NRT-08:1.1
	VAM1-00:1.1
	V4-21:1.1.0.4
	V4-13:1.1
	V4-12:1.1
	V4-11:1.1
	V4-10:1.1
	V3-43:1.1
	M4-00:1.1
	V3-41:1.1
	V3-40-PlusGM57:1.1.0.2
	V3-33:1.1
	V3-31:1.1
	V3-30-NRT-05:1.1
	cfm-01-00:1.1
	V3-30:1.1
	V3-20:1.1
	V3-10:1.1;
locks; strict;
comment	@% @;


1.1
date	2008.06.11.20.14.52;	author vsnyder;	state Exp;
branches;
next	;


desc
@@


1.1
log
@Initial commit
@
text
@\documentclass[11pt]{article}
\usepackage[fleqn]{amsmath}\textwidth 6.5in
\oddsidemargin -0.25in
%\evensidemargin -0.5in
%\topmargin -0.65in
%\textheight 9.3in

\newcommand{\docname}{\bf wvs-035}
\newcommand{\docdate}{13 June 2006}

\begin{document}

%\tracingcommands=1
\newlength{\hW} % heading box width
\newlength{\pW} % page number field width
\settowidth{\hW}{\docname}
\settowidth{\pW}{Page \pageref{lastpage}\ of \pageref{lastpage}}
\ifdim \pW > \hW \setlength{\hW}{\pW} \fi
\makeatletter
\def\@@biblabel#1{#1.}
\newcommand{\ps@@twolines}{%
  \renewcommand{\@@oddhead}{%
    \docdate\hfill\parbox[t]{\hW}{{\hfill\docname}\newline
                          Page \thepage\ of \pageref{lastpage}}}%
\renewcommand{\@@evenhead}{}%
\renewcommand{\@@oddfoot}{}%
\renewcommand{\@@evenfoot}{}%
}%
\makeatother
\pagestyle{twolines}

\vspace{-10pt}
\begin{tabbing}
\phantom{References: }\= \\
To: \>Bill, Fred, Herb, Nathaniel\\
Subject: \>Alternative to gradient move in DNWT\\
From: \>Van Snyder\\
\end{tabbing}

\parindent 0pt \parskip 6pt
\vspace{-20pt}

Denote the best solution that DNWT has found and the current solution by
$\mathbf{F}_b$ and $\mathbf{F}_c$, respectively, their norms by $F_b$ and
$F_c$, respectively, the states at which these solutions were computed by
$\mathbf{x}_b$ and $\mathbf{x}_c$, respectively, and $\nabla
F(\mathbf{x})|_{\mathbf{x}=\mathbf{x}_b}$ and $\nabla
F(\mathbf{x})|_{\mathbf{x}=\mathbf{x}_c}$ by $\nabla F_b$ and $\nabla
F_c$, respectively.

Assume that $\mathbf{x}_b \neq \mathbf{x}_c$, $F_b
<F_c$, and DNWT has decided not to take another Newton move from
$\mathbf{x}_c$, usually because the linear neighborhood of $\mathbf{x}_c$
appears not to have a solution better than $F_b$.

At present, when DNWT finds itself in this situation, it computes
successively smaller values of $g$ until $F(\mathbf{x}_b + g \nabla F_b)
< F_b$, then takes Newton moves starting from $\mathbf{x}_b + g \nabla
F_b$ with initially substantial and later decreasing restrictions on
their lengths, the restrictions being imposed by Levenberg-Marquardt
stabilization that initially depends upon $g||\nabla F_b||$ and then
decreases with each successful Newton move.  The rationale for this is
that a sufficiently short gradient move will reduce $F$, and gradient
moves are essentially free in the sense that one has saved enough
information to compute the move without needing to reevaluate $F$ or the
Jacobian matrix at $\mathbf{x}_b$ in order to compute the move, although
one does need to compute $F(\mathbf{x}_b + g \nabla F_b)$.  Since we
compute $\mathbf{F}$ and its Jacobian matrix at the same time, one hopes
that the initial choice of $g$ results in a decrease in $F$.  An
alternative is to revise DNWT so that its {\tt EVALF} return means
``evaluate $F$ only, and I promise not to ask for a Newton move'' and
have a different return that means ``Compute $F$ and $\mathbf{J}$.'' 
This would be a substantial revision, both in DNWT and the retriever.

Herb has suggested to search along the line from $\mathbf{x}_b$ to
$\mathbf{x}_c$, to find a state for which the solution is better than
$F_b$.  Since searching is expensive because we compute both $\mathbf{F}$
and its Jacobian matrix, this note describes how to determine whether to
expect an improvement along that line, and how to choose a point where
the improvement is expected to be optimal.

DNWT expects the calling program unit to save $F_b$, $\nabla
F_b$, $\mathbf{x}_b$, $F_c$, $\nabla F_c$, and
$\mathbf{x}_c$.

Compute $\delta \mathbf{x} = \mathbf{x}_c - \mathbf{x}_b$.  The
directional derivatives at $b$ and $c$ are given by $\left.
\frac{\text{d} F}{\text{d} \delta \mathbf{x}}
\right|_{\mathbf{x}=\mathbf{x}_b} = \delta \mathbf{x} \cdot \nabla
F_b$ and  $\left. \frac{\text{d} F}{\text{d} \delta
\mathbf{x}} \right|_{\mathbf{x}=\mathbf{x}_c} = \delta \mathbf{x} \cdot
\nabla F_c$.  If $\left. \frac{\text{d} F}{\text{d}
\delta \mathbf{x}} \right|_{\mathbf{x}=\mathbf{x}_b} < 0$ there are
values of $\hat\xi$ such that $0 < \hat\xi < 1$ and $F(\mathbf{x}_b +
\hat\xi \delta \mathbf{x}) < F_b$.  Furthermore, if $\left.
\frac{\text{d} F}{\text{d} \delta \mathbf{x}}
\right|_{\mathbf{x}=\mathbf{x}_c} > 0$, there are values of $\hat\xi$ such
that $0 < \hat\xi < 1$ and $F(\mathbf{x}_c - \hat\xi \delta
\mathbf{x}) < F_c$.

Having $F_b$, $\nabla F_b$, $\mathbf{x}_b$, $F_c$, $\nabla F_c$, and
$\mathbf{x}_c$, it is possible to interpolate a cubic polynomial
$P_3(\xi)$ along the line from $\mathbf{x}_b$ to $\mathbf{x}_c$ using
Hermite interpolation, where $0 < \xi < 1$ is the fraction of the
distance from $\mathbf{x}_b$ to $\mathbf{x}_c$.  Under the above
conditions, there is one zero $\hat\xi$ of $P_3^\prime(\xi)$,
equivalently one minimum of $P_3(\xi)$ such that $0 < \hat\xi < 1$.  One
can hope that, if $P_3(\xi)$ is a reasonable model for $F$ along that
line, $\hat\xi$ will be such that $F(\mathbf{x}_b + \hat\xi \delta
\mathbf{x}) < F_b$.

To compute $\hat\xi$ let $\delta \mathbf{\hat x} = \delta \mathbf{x} /
||\delta \mathbf{x}||$, and write $P_3^\prime(\xi)$ as $3 a_3 \xi^2 + 2
a_2 \xi +a_1$.  The coefficients $a_1$, $a_2$ and $a_3$ are gotten by
Hermite interpolation, having the values $a_1 = \delta \mathbf{\hat x}
\cdot \nabla F_b$, $a_2 = 3 ( F_c - F_b ) - 2 \delta \mathbf{\hat x}
\cdot \nabla F_b - \delta \mathbf{\hat x} \cdot \nabla F_c$ and $a_3 = -
2 ( F_c - F_b ) + \delta \mathbf{\hat x} \cdot \nabla F_b + \delta
\mathbf{\hat x} \cdot \nabla F_c$.  At the zeros of $P_3^\prime(\xi)$, we
have $\hat\xi = -\frac13 \frac{a_2 \pm \sqrt{a_2^2 - 3 a_1 a_3}}{a_3}$. 
Under the conditions stated above, both values of $\hat\xi$ are real, and
there is one value $0 < \hat\xi_\vee < 1$ at which $P_3(\xi)$ has a
minimum (and one uninteresting value $\hat\xi_\wedge$ outside that range
at which $P_3(\xi)$ has a local maximum).

Compute $F_t = F(\mathbf{x}_b + \hat\xi_\vee \delta \mathbf{x})$.

If $F_t < F_b$ set $\mathbf{x}_b := \mathbf{x}_t$ and
$F_b := F_t$, and continue from $\mathbf{x}_t$ using
Newton moves.  This leaves open the question what Levenberg-Marquardt
stabilization ought to be imposed at this point.  Perhaps the same
strategy as is presently used after gradient moves would be appropriate.

If $F_t \geq F_b$ there are at least two possibilities.  One is to
continue from $\mathbf{x}_b$ using gradient moves as described above. 
The other is to fit a quadratic polynomial $P_2$ to $(\mathbf{x}_b,F_b)$,
$(\mathbf{x}_t,F_t)$ and $(\mathbf{x}_c,F_c)$, and find a value
$\tilde{\mathbf{x}}_t$ at which $P_2$ is minimal.  The latter process can
be iterated using values of $F$ alone, that is, without computing $\nabla
F$ or the Jacobian matrix.  As above, exploiting this would require
substantial revision of both DNWT and the solver.

We should wait to do anything along these lines until we observe that
DNWT takes gradient moves when the retriever is properly configured,
i.e., when bounds are properly specified.  If that is ever observed, it
may be worthwhile at that time to investigate whether this approach is
fruitful.

\label{lastpage}
\end{document}
% $Id: $
@
