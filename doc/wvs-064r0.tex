\documentclass[11pt]{article}
\usepackage[fleqn]{amsmath}\textwidth 6.5in
\oddsidemargin -0.25in
%\evensidemargin -0.5in
\topmargin -0.25in
\textheight 9in

\newcommand{\docname}{\bf wvs-064}
\newcommand{\docdate}{29 November 2007}

\begin{document}

%\tracingcommands=1
\newlength{\hW} % heading box width
\newlength{\pW} % page number field width
\settowidth{\hW}{\docname}
\settowidth{\pW}{Page \pageref{lastpage}\ of \pageref{lastpage}}
\ifdim \pW > \hW \setlength{\hW}{\pW} \fi
\makeatletter
\def\@biblabel#1{#1.}
\newcommand{\ps@twolines}{%
  \renewcommand{\@oddhead}{%
    \docdate\hfill\parbox[t]{\hW}{{\hfill\docname}\newline
                          Page \thepage\ of \pageref{lastpage}}}%
\renewcommand{\@evenhead}{}%
\renewcommand{\@oddfoot}{}%
\renewcommand{\@evenfoot}{}%
}%
\makeatother
\pagestyle{twolines}

\vspace{-10pt}
\begin{tabbing}
\phantom{References: }\= \\
To: \>Dave\\
Subject: \>Summary of summary of changes made to reduce MLSL2 run time\\
From: \>Van Snyder\\
Reference: \>wvs-055
\end{tabbing}

\parindent 0pt \parskip 6pt
\vspace{-10pt}

Dave asked me to investigate whether using hardware-assist devices based upon
FPGA or DSP chips might provide a substantial reduction in MLSL2 run time. This
got me started investigating where MLSL2 spends its time.

Paul gave me an {\tt l2cf} named {\tt nopcf\_v02-21-c01\_2005d028.l2cf}, which
is representative of our production processing configuration.  All of the
performance improvements were tuned to this l2cf.

Actions and performance improvements are summarized in the following table.

\begin{tabular}{p{5in}|r}
\hline
                                                                   & Resulting\\
What I did                                                         & Run time \\
\hline
Compile with Lahey/Fujitsu v6.1, program as of 3 May 2007             & 42942 \\
Compile with Intel 10.0.023 using {\tt -O3 -xW -no-prec-div}          & 29178 \\
Improve cache locality in {\tt get\_do\_calc} by avoiding vector
 subscripts                                                           & * \\
Use assumed-size arguments in {\tt get\_do\_calc} and {\tt dfft}
 (Lahey/Fujitsu only)                                                 & * \\
Use ATLAS blas instead of {\tt dot\_product} (Lahey/Fujitsu and NAG)  & * \\
Use Fortran reference BLAS instead of {\tt dot\_product} (Intel only) & * \\
Change {\tt slabs\_struct} from structure of arrays to array of
 structures, thereby substantially improving cache locality;
 replace pointer components by allocatable components (an extension of
 Fortran 95)                                                          & * \\
Revise {\tt d\_delta\_df} representation to exploit sparsity          & 24243 \\
Replace full FFT in antenna convolution by cosine transform           & 23806 \\
Revise representation of {\tt eta} from {\tt get\_eta\_sparse\_2d\_nz},
used in {\tt comp\_\-eta\_docalc\_no\_frq}, again to exploit sparsity & 21020 \\
Use revised representation of {\tt eta} in {\tt dt\_scr\_dt} to exploit
sparsity                                                              & 19691 \\
\hline
Note *: Can't find record of run time; I have it somewhere.\\
\hline
\end{tabular}

We couldn't use ATLAS BLAS dot product with the Intel compiler because {\tt
gcc} uses the floating-point stack pointer differently from how the Intel
compiler expects it to, resulting in NaNs.

We have had to stop using the {\tt -O3 -xW -no-prec-div} options with the Intel
compiler because at least one of them (maybe a conspiracy of them) results in
non-repeatable results.

These two disappointments have increased run times significantly from the best
we achieved, but the overall improvement is still substantial.

\label{lastpage}
\end{document}
% $Id$
